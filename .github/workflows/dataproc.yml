name: Daily Data Processing Workflow

on:
  schedule:
    - cron: '0 21 * * *'  # 9 PM UTC daily
  workflow_dispatch:

permissions:
  contents: write

jobs:
  run_scripts:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.x'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install slack_sdk reportlab boto3 pymupdf python-pptx openpyxl nltk openai==0.28

      - name: Run slackintegrationgit.py and capture output
        id: slack
        run: |
          python slackintegrationgit.py | tee slack_output.log
          # Check if PDF was generated and uploaded
          if grep -q "Uploaded hcmsupportbot_" slack_output.log; then
            echo "pdf_status=generated" >> $GITHUB_OUTPUT
          elif grep -q "No messages found for today." slack_output.log; then
            echo "pdf_status=none" >> $GITHUB_OUTPUT
          else
            echo "pdf_status=error" >> $GITHUB_OUTPUT
          fi
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          SLACK_BOT_TOKEN: ${{ secrets.SLACK_BOT_TOKEN }}

      - name: Download or use existing document store
        run: |
          python -c "
          import boto3
          import os
          import shutil
          
          # Check if document_store.pkl exists in S3
          s3 = boto3.client('s3')
          try:
              s3.head_object(Bucket='hcmbotknowledgesource', Key='document_store.pkl')
              # If it exists, download it
              s3.download_file('hcmbotknowledgesource', 'document_store.pkl', 'document_store.pkl')
              print('Downloaded existing document store from S3')
          except Exception as e:
              # If it doesn't exist or there's an error, use the local file
              if os.path.exists('documen_store_og.pkl'):
                  shutil.copy('documen_store_og.pkl', 'document_store.pkl')
                  print('Using documen_store_og.pkl from repository as initial document store')
              else:
                  print(f'Could not download document store and documen_store_og.pkl not found: {e}')
          "
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}

      - name: Run chromaraggit.py
        if: steps.slack.outputs.pdf_status == 'generated'
        run: python chromaraggit.py
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}

      - name: Upload updated document store to S3
        if: steps.slack.outputs.pdf_status == 'generated'
        run: |
          python -c "
          import boto3
          s3 = boto3.client('s3')
          try:
              s3.upload_file('document_store.pkl', 'hcmbotknowledgesource', 'document_store.pkl')
              print('Uploaded updated document store to S3')
          except Exception as e:
              print(f'Could not upload document store: {e}')
          "
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}

      - name: Create .gitignore
        run: |
          # Create or update .gitignore to exclude temporary files
          if [ ! -f .gitignore ]; then
            echo "pdfs2/" > .gitignore
            echo "slack_output.log" >> .gitignore
            echo "*.log" >> .gitignore
            echo "*.pkl" >> .gitignore
          else
            grep -q "pdfs2/" .gitignore || echo "pdfs2/" >> .gitignore
            grep -q "slack_output.log" .gitignore || echo "slack_output.log" >> .gitignore
            grep -q "*.log" .gitignore || echo "*.log" >> .gitignore
            grep -q "*.pkl" .gitignore || echo "*.pkl" >> .gitignore
          fi
